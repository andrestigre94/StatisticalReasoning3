---
title: "StatisticalReasoning3"
author: "HannahHayes&AndresTigreros"
format: pdf
editor: visual
---

Let's start by reading in the relevant packages

```{r eval=FALSE}
library(brms) # for statistics
library(tidyverse) # for data wrangling
library(rethinking)
library(dagitty)

# a function to scale and center. from rethinking package
standardize <- function(x) {
    x <- scale(x)
    z <- as.numeric(x)
    attr(z,"scaled:center") <- attr(x,"scaled:center")
    attr(z,"scaled:scale") <- attr(x,"scaled:scale")
    return(z)
}
```

# 1. DAG practice

![example DAG](example_dag.jpg)

Directed Acyclic Graphs (DAGs) represent our understanding of causal influences in a system, with arrows connecting causes to effects. Consider the DAG above.

Now recreate the DAG above on [dagitty.net](https://dagitty.net). Leave the window open, as we'll be using it more.

### Q1.1 Make a DAG

Please paste either your DAG image from the website or the DAG model code here.

ANSWER:

```{r}
drawdag('dag {
  A [adjusted,pos="-0.423,-1.288"]
  B [adjusted,pos="-0.423,-0.713"]
  C [adjusted,pos="0.083,-0.962"]
  U [adjusted,pos="-0.942,-0.962"]
  X [adjusted,pos="-0.939,-0.103"]
  Y [adjusted,pos="0.112,-0.095"]
  A -> C
  A -> U
  C -> B
  C -> Y
  U -> B
  U -> X
  X -> Y
}')

```

------------------------------------------------------------------------

There are four fundamental relations in a DAG: the fork, the pipe, the collider, and the descendent. This image shows them:

![elemental confounds](elemental_confounds.jpg)

### Q1.2 Identify forks

Which forks do you see in the DAG you made on dagitty.net? Please write them out in a Quarto list (look up how to write a list if you don't remember!) in the form L ← M → N.

ANSWER: Forks are

U \<- A -\> C

X \<- U -\> B

B \<- C -\> Y

------------------------------------------------------------------------

### Q1.3 Identify colliders

Which colliders do you see? Please write them out in a Quarto list in the form L → M ← N. Hint: there is more than one!

ANSWER: Colliders are

U -\> B \<- C

X -\> Y \<- C

------------------------------------------------------------------------

### Q1.4 Modify the DAG

Now modify the DAG (it should still be open on dagitty.net) to include the variable V, an unobserved cause of C and Y: C ← V → Y. Please paste either your DAG image from the website or the DAG model code here.

```{r}
drawdag('dag {
A [adjusted,pos="-0.423,-1.288"]
B [adjusted,pos="-0.423,-0.713"]
C [adjusted,pos="0.083,-0.962"]
U [adjusted,pos="-0.942,-0.962"]
V [adjusted,pos="0.410,-0.571"]
X [adjusted,pos="-0.939,-0.103"]
Y [adjusted,pos="0.112,-0.095"]
A -> C
A -> U
C -> B
C -> Y
U -> B
U -> X
V -> C
V -> Y
X -> Y
}')
```

------------------------------------------------------------------------

### Q1.5 Identify paths

Reanalyze this new DAG. How many paths connect X to Y? Please list them in a Quarto list here:

ANSWER: We identified 5 different paths

X -\> Y

X \<- U -\> B \<- C -\> Y

X \<- U -\> B \<- C \<- V \<- Y

X \<- U \<- A -\> C -\> Y

X \<- U \<- A -\> C \<- V -\> Y

------------------------------------------------------------------------

### Q1.6 Identify open backdoor paths

Which paths must be closed to estimate the direct effect of X on Y? List the paths

ANWER: The open backdoor paths is one. This because there are 4 backdoor path between X and Y that, but just one do not hit with a collider and this is the one that must be closed.

X \<- U \<- A -\> C -\> Y

------------------------------------------------------------------------

### Q1.7 Identify variables to close the backdoor(s)

Given what you just wrote about paths to close, which variables should you condition on to estimate the direct effect of X on Y in your new DAG?

ANSWER: We have three closed backdoors. This because the other three paths hit with a collider at some point

X \<- U -\> B \<- C -\> Y

X \<- U -\> B \<- C \<- V \<- Y

X \<- U \<- A -\> C \<- V -\> Y

So, in order to estimate the effect, me wust condition on U or A. When we condition, we create a correlation between the ones that collide with that variable.

------------------------------------------------------------------------

# 2. Foxes: Regression practice informed by DAGs

For this section, we are going to implement what we learned about DAGs into an example about urban fox territories from the `rethinking` package. Let's load in the data:

```{r}
# Load in the fox data 
foxes <- read.csv('https://raw.githubusercontent.com/rmcelreath/rethinking/refs/heads/master/data/foxes.csv', sep = ';')
```

```{r}
# Check out the fox data 
?foxes 
head(foxes)
```

From the Rethinking textbook: "The data in data(foxes) are 116 foxes from 30 different urban groups in England. These foxes are like street gangs. `Group size` varies from 2 to 8 individuals. Each group maintains its own urban territory. Some territories are larger than others. The `area` variable encodes this information. Some territories also have more `avgfood` than others. We want to model the `weight` of each fox \[in kg\]." For the questions below, we will assume the following DAG is appropriate for this system:

![fox DAG](foxDAG.jpg){alt="fox DAG"}

------------------------------------------------------------------------

![elemental confounds](elemental_confounds.jpg){alt="elemental confounds"}

### Q2.1 Identify the fundamental relations in the fox DAG

Which of the first three fundamental relations above (Fork, Pipe, and Collider) do you see in the Fox DAG? List the names of the relations you see AND the particular paths (e.g. "Pipe1: X-\>Z-\>Y, Pipe2: X-\>Z-\>C and Fork1: X\<-Z-\>Y")

ANSWER:

-   Forks: weight \<- avfood -\> grpsize

-   Pipes: area -\> avgfood -\> weight ; area -\> grpsize -\>weight

-   Colliders: avgfood -\> weight \<- grpsize

------------------------------------------------------------------------

## Total causal influence of area on weight

In this first part we are going to infer the total causal influence of area on weight. Would increasing the area available to each fox make it heavier (healthier)?

-   First, we will standardize the variables.
-   Second, we will use prior predictive simulation to check that our model’s prior predictions stay within a reasonable outcome range.
-   Third, we will run and interpret the models.

Standardize weight to mean zero and standard deviation of 1

```{r}
fox_dat <- foxes %>%
  as_tibble() %>%
  select(area, avgfood, weight, groupsize) %>%
  mutate(across(everything(), standardize))
head(fox_dat)
```

Simulate from some priors for a linear regression with intercept *alpha* and slope *beta*: *alpha* \~ Gaussian(0, 0.2), *beta* \~ Gaussian(0, 2)

```{r}
n <- 1000
priorsims <- tibble(group = seq_len(n),
       alpha = rnorm(n, 0, 0.2), # prior for alpha
       beta = rnorm(n, 0, 2)) %>% # prior for beta
  expand(nesting(group, alpha, beta), # the expand function gives us all possible combinations of the arguments
         area = seq(from = -2, to = 2, length.out = 100)) %>% # set up a range of areas
  mutate(weight = alpha + beta * area) # calculate weight from the parameters and area
```

Make a plot of what these priors imply.

```{r}
ggplot(priorsims, aes(x = area, y = weight, group = group)) +
  geom_line(alpha = 1 / 10) +
  labs(x = "Standardized Area", y = "Standardized Weight")
```

It's pretty hard to understand what a "reasonable" fox weight is when it is in standardized units. Let's logic our way through this slowly.

------------------------------------------------------------------------

### Q2.2 Minimum fox weight

What to you seems like a reasonable minimum weight for a fox, in kg?

```{r}
min(foxes$weight)
```

------------------------------------------------------------------------

### Q2.3 Maximum fox weight

What to you seems like a reasonable minimum weight for a fox, in kg?

```{r}
max(foxes$weight)
```

------------------------------------------------------------------------

### Q2.4 Modify simulation plot

Remake your prior predictive simulation plot and add two horizontal lines, one each for the minimum and maximum weights that you just provided. Before plotting, make sure to *standardize* your values in kg so that they are plotted as centered values in units of standard deviation (i.e., subtract the mean and divide by the standard deviation of foxes\$weight).

```{r}
##Defining the max and min
raw_min <- 1.92
raw_max <- 7.55

##Calculating the standardized versions
##We subtract the mean and divide by the standard deviation of foxes$weight
std_min <- (raw_min - mean(foxes$weight)) / sd(foxes$weight)
std_max <- (raw_max - mean(foxes$weight)) / sd(foxes$weight)


##Plotting now

ggplot(priorsims, aes(x = area, y = weight, group = group)) +
  geom_line(alpha = 1 / 10) +
  labs(x = "Standardized Area", y = "Standardized Weight") +
  geom_hline(yintercept = std_min, linetype = "dashed", color = "red") +
  geom_hline(yintercept = std_max, linetype = "dashed", color = "red") +
  labs(x = "Standardized Area", y = "Standardized weight") +
  theme_classic()
```

------------------------------------------------------------------------

### Q2.5 Evaluate prior predictive simulation

Do your priors seem reasonable? You haven't seen any data yet, though you have marked out the minimum and maximum weights you expect foxes to be. Do your priors greatly exceed those values? Please explain your thinking.

ANSWER: It seems like the priors are not really informative because they are far away deviated from the a realistic weight in foxes which are depicted by the red lines in the last graph.

------------------------------------------------------------------------

### Q2.6 Refine priors

Remake and plot a set of prior simulations that use priors you think are reasonable (adjusting the code from above would work well for this). Be sure to include the minimum and maximum fox weights that you expect. You can iterate on this a few times (simulate, plot, adjust, etc.) until you arrive at priors that make sense to you.

```{r}
n <- 1000

## tightening the beta from 2.0 to 0.5 so the slope is not that pronounced. 2 was to wide so it showed a lot of really fat foxes
priorsims_refined <- tibble(group = seq_len(n),
                    alpha = rnorm(n, 0, 0.2), 
                    beta = rnorm(n, 0, 0.5)) %>% 
  expand(nesting(group, alpha, beta), 
         area = seq(from = -2, to = 2, length.out = 100)) %>% 
  mutate(weight = alpha + beta * area)

# Plot it again and see if this change worked hehe
ggplot(priorsims_refined, aes(x = area, y = weight, group = group)) +
  geom_line(alpha = 1 / 10) +
  geom_hline(yintercept = std_min, linetype = "dashed", color = "red") +
  geom_hline(yintercept = std_max, linetype = "dashed", color = "red") +
  labs(x = "Standardized Area", y = "Standardized weight") +
  theme_classic()
```

## Run models

Run a model predicting average food as a function of area. Modify the code for the priors below to match the priors you just chose.

```{r eval=FALSE}
food_on_area <- brm(avgfood ~ 1 + area, 
                    data = fox_dat, 
                    family = gaussian,
                    # Here we set the priors that we investigated earlier
                    prior = c(prior(normal(0, 0.2), class = Intercept),
                              prior(normal(0, 2), class = b,),
                              prior(exponential(1), class = sigma)),
                    iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                    file = "output/food_on_area")
```

Checking the summary

```{r}
summary(food_on_area)
```

We see a fairly strong effect of area on the average amount of food. Because we standardized each variable by standard deviations, our units are now in "standard deviations". (*We can backtransform these value to translate this back to the normal units! We won't do that here, as we'll get a lot more practice with that when we get to generalized linear models, but just know that if you are annoyed by the unitless values, there's a way out!*)

We find that for an increase of 1 standard deviation in area, we expect to see a 0.88 standard deviation increase in food. The 95% compatibility interval for the area parameter is 0.79 to 0.96, which does not include zero. Logically this makes sense, as a greater area would have more prey available.

------------------------------------------------------------------------

### Q2.7 Run a model for the impact of food on fox weight

Now infer the total impact of adding food to a territory. Run a model with `weight` as a function of `avgfood`. Based on your results, does more food make foxes heavier? In your opinion, is this expected or unexpected? Please explain in two (2) or more sentences.

```{r eval=FALSE}
food_on_weight <- brm(weight ~ 1 + avgfood, 
                    data = fox_dat, 
                    family = gaussian,
                    # Here we set the priors that we investigated earlier
                    prior = c(prior(normal(0, 0.2), class = Intercept),
                              prior(normal(0, 2), class = b,),
                              prior(exponential(1), class = sigma)),
                    iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
                    file = "output/food_on_weight")
```

```{r}
summary(food_on_weight)
```

ANSWER: The model ran correctly because our Rhat's are perfectly on a vlue of 1.00. Here in this we didn't find the existence of an effect of avgfood in the weight of foxes. This due to the lower and upper CI went acroos zero. This is quite unexpected for us because you'd normally assumed that the amound of food will impact the weight of animals.

------------------------------------------------------------------------

### Q2.8 Is there a variable we should condition upon?

We just estimated the total impact of `avgfood` on `weight`, which includes both direct and indirect paths. Think back to your DAG elemental confounds. If we want to estimate only the direct impact of `avgfood` on `weight`, which variable should we condition upon?

ANSWER: We think that we must condition on groupsize becase avgfood also impact this variable following our DAG. So, groupsize also has an influence in the weight of foxes

------------------------------------------------------------------------

## Add in `groupsize`

In the previous model we saw no effect of `avgfood` on fox `weight`, but we have an extra path that we need to account for, since `avgfood` flows to `weight` through `groupsize`.

First, let's look at the separate effect of `groupsize` in a univariate regression, just like with `avgfood`.

------------------------------------------------------------------------

### Q2.9: What's your hypothesis about how group size affects fox weight?

Before running the model, how do you think the number of foxes in a group `groupsize` would affect fox weight? Why?

------------------------------------------------------------------------

Now let's run the model:
